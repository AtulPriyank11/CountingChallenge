{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import AutoProcessor, GroundingDinoForObjectDetection\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "import detectron2.data.detection_utils as utils\n",
    "from detectron2.data import build_detection_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*loading.*\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*CUDA.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize processor and model\n",
    "processor = AutoProcessor.from_pretrained(\"IDEA-Research/grounding-dino-tiny\")\n",
    "model = GroundingDinoForObjectDetection.from_pretrained(\"IDEA-Research/grounding-dino-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_exif(image_path):\n",
    "    \"\"\"Remove EXIF data to prevent issues with image size.\"\"\"\n",
    "    with Image.open(image_path) as img:\n",
    "        img = img.convert(\"RGB\")\n",
    "        img.save(image_path, \"JPEG\")\n",
    "\n",
    "def generate_annotations_for_folder(folder_path, category_id, text_prompt):\n",
    "    annotations = []\n",
    "    images_info = []\n",
    "    image_id = 0\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith((\".jpg\", \".png\")):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            remove_exif(image_path)\n",
    "\n",
    "            with Image.open(image_path) as image:\n",
    "                width, height = image.size\n",
    "                inputs = processor(images=image, text=text_prompt, return_tensors=\"pt\")\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**inputs)\n",
    "\n",
    "                target_sizes = torch.tensor([image.size[::-1]])\n",
    "                results = processor.image_processor.post_process_object_detection(\n",
    "                    outputs, threshold=0.1, target_sizes=target_sizes\n",
    "                )[0]\n",
    "\n",
    "                for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "                    box = [round(i * width if idx % 2 == 0 else i * height, 1) for idx, i in enumerate(box.tolist())]\n",
    "\n",
    "                    if box[2] < box[0] or box[3] < box[1]:\n",
    "                        continue\n",
    "                    \n",
    "                    annotation = {\n",
    "                        \"id\": len(annotations),\n",
    "                        \"image_id\": image_id,\n",
    "                        \"bbox\": box,\n",
    "                        \"score\": score.item(),\n",
    "                        \"category_id\": category_id,\n",
    "                        \"iscrowd\": 0,\n",
    "                        \"area\": (box[2] - box[0]) * (box[3] - box[1])\n",
    "                    }\n",
    "                    annotations.append(annotation)\n",
    "                \n",
    "                images_info.append({\n",
    "                    \"id\": image_id,\n",
    "                    \"file_name\": filename,\n",
    "                    \"width\": width,\n",
    "                    \"height\": height\n",
    "                })\n",
    "                \n",
    "                image_id += 1\n",
    "\n",
    "    return images_info, annotations\n",
    "\n",
    "def save_annotations_to_coco_format(images_info, annotations, output_path):\n",
    "    coco_format = {\n",
    "        \"images\": images_info,\n",
    "        \"annotations\": annotations,\n",
    "        \"categories\": [{\"id\": 1, \"name\": \"screw\"}, {\"id\": 2, \"name\": \"bolt\"}]\n",
    "    }\n",
    "    \n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(coco_format, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "screws_folder = \"C:/Users/atulp/Downloads/perspectiv_labs/data/Screws_2024_07_15/\"\n",
    "screws_and_bolts_folder = \"C:/Users/atulp/Downloads/perspectiv_labs/data/ScrewAndBolt_20240713/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate annotations\n",
    "screws_images, screws_annotations = generate_annotations_for_folder(\n",
    "    screws_folder, category_id=1, text_prompt=\"Find many individual small screws, focusing on their shape and size.\"\n",
    ")\n",
    "screws_and_bolts_images, screws_and_bolts_annotations = generate_annotations_for_folder(\n",
    "    screws_and_bolts_folder, category_id=2, text_prompt=\"Locate many individual small screws and many individual small bolts, focusing on their distinct shape and size.\"\n",
    ")\n",
    "\n",
    "# Save annotations in COCO format\n",
    "save_annotations_to_coco_format(\n",
    "    screws_images, screws_annotations, \"C:/Users/atulp/Downloads/perspectiv_labs/AI/annotations/screws_annotations.json\"\n",
    ")\n",
    "save_annotations_to_coco_format(\n",
    "    screws_and_bolts_images, screws_and_bolts_annotations, \"C:/Users/atulp/Downloads/perspectiv_labs/AI/annotations/screws_and_bolts_annotations.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register datasets with Detectron2\n",
    "def register_coco_dataset(name, json_file, image_root):\n",
    "    register_coco_instances(name, {}, json_file, image_root)\n",
    "\n",
    "def visualize_annotations(dataset_name, image_folder):\n",
    "    metadata = MetadataCatalog.get(dataset_name)\n",
    "    dataset_dicts = DatasetCatalog.get(dataset_name)\n",
    "    \n",
    "    output_folder = os.path.join(image_folder, \"visualizations\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    for d in dataset_dicts:\n",
    "        img_path = os.path.join(image_folder, d[\"file_name\"])\n",
    "        image = utils.read_image(img_path, format=\"BGR\")\n",
    "        \n",
    "        v = Visualizer(image[:, :, ::-1], metadata=metadata, instance_mode=ColorMode.IMAGE)\n",
    "        out = v.draw_dataset_dict(d)\n",
    "        vis_image = out.get_image()[:, :, ::-1]\n",
    "        vis_image_pil = Image.fromarray(vis_image)\n",
    "        \n",
    "        output_image_path = os.path.join(output_folder, os.path.basename(d[\"file_name\"]))\n",
    "        vis_image_pil.save(output_image_path)\n",
    "        print(f\"Annotation visualization saved to {output_image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register datasets\n",
    "register_coco_dataset(\"screws\", \"C:/Users/atulp/Downloads/perspectiv_labs/AI/annotations/screws_annotations.json\", \"C:/Users/atulp/Downloads/perspectiv_labs/data/Screws_2024_07_15/\")\n",
    "register_coco_dataset(\"screws_and_bolts\", \"C:/Users/atulp/Downloads/perspectiv_labs/AI/annotations/screws_and_bolts_annotations.json\", \"C:/Users/atulp/Downloads/perspectiv_labs/data/ScrewAndBolt_20240713/\")\n",
    "\n",
    "visualize_annotations(\"screws\", \"C:/Users/atulp/Downloads/perspectiv_labs/data/Screws_2024_07_15/\")\n",
    "visualize_annotations(\"screws_and_bolts\", \"C:/Users/atulp/Downloads/perspectiv_labs/data/ScrewAndBolt_20240713/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "def train_retinanet():\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_50_FPN_3x.yaml\"))\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/retinanet_R_50_FPN_3x.yaml\")\n",
    "    cfg.DATASETS.TRAIN = (\"screws_and_bolts_train\",)\n",
    "    cfg.DATASETS.TEST = (\"screws_val\",)\n",
    "    cfg.DATALOADER.NUM_WORKERS = 2\n",
    "    cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "    cfg.SOLVER.BASE_LR = 0.00025\n",
    "    cfg.SOLVER.MAX_ITER = 500\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
    "    cfg.MODEL.DEVICE = \"cpu\"\n",
    "    cfg.OUTPUT_DIR = \"./output\"\n",
    "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "    trainer = DefaultTrainer(cfg)\n",
    "    trainer.resume_or_load(resume=False)\n",
    "    trainer.train()\n",
    "\n",
    "    return cfg\n",
    "\n",
    "# Train the model\n",
    "cfg = train_retinanet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(cfg):\n",
    "    test_loader = build_detection_test_loader(cfg, \"screws_val\")\n",
    "    evaluator = COCOEvaluator(\"screws_val\", cfg, False, output_dir=cfg.OUTPUT_DIR)\n",
    "    print(\"Evaluating the model...\")\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    results = inference_on_dataset(predictor.model, test_loader, evaluator)\n",
    "    print(results)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Metadata and visualize results\n",
    "MetadataCatalog.get(\"screws_train\").thing_classes = [\"screw\", \"bolt\"]\n",
    "MetadataCatalog.get(\"screws_and_bolts_val\").thing_classes = [\"screw\", \"bolt\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_objects_in_images(image_folder, output_folder, cfg):\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    metadata = MetadataCatalog.get(cfg.DATASETS.TRAIN[0])\n",
    "    \n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    for filename in os.listdir(image_folder):\n",
    "        if filename.lower().endswith((\".jpg\", \".png\")):\n",
    "            image_path = os.path.join(image_folder, filename)\n",
    "            image = utils.read_image(image_path, format=\"BGR\")\n",
    "            outputs = predictor(image)\n",
    "            predictions = outputs[\"instances\"].to(\"cpu\")\n",
    "            \n",
    "            num_objects = len(predictions)\n",
    "            print(f\"Image: {filename}, Number of objects detected: {num_objects}\")\n",
    "\n",
    "            if num_objects == 0:\n",
    "                print(f\"No objects detected in {filename}.\")\n",
    "                continue\n",
    "\n",
    "            valid_predictions = predictions[predictions.pred_classes < cfg.MODEL.ROI_HEADS.NUM_CLASSES]\n",
    "\n",
    "            if len(valid_predictions) == 0:\n",
    "                print(f\"No valid predictions for {filename}.\")\n",
    "                continue\n",
    "\n",
    "            v = Visualizer(image[:, :, ::-1], metadata=metadata, instance_mode=ColorMode.IMAGE)\n",
    "            try:\n",
    "                out = v.draw_instance_predictions(valid_predictions)\n",
    "                vis_image = out.get_image()[:, :, ::-1]\n",
    "                vis_image_pil = Image.fromarray(vis_image)\n",
    "                \n",
    "                output_image_path = os.path.join(output_folder, filename)\n",
    "                vis_image_pil.save(output_image_path)\n",
    "                print(f\"Visualized image saved to {output_image_path}\")\n",
    "            except IndexError as e:\n",
    "                print(f\"Error visualizing {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform object counting and visualization\n",
    "count_objects_in_images(\"C:/Users/atulp/Downloads/perspectiv_labs/data/ScrewAndBolt_20240713/\", \n",
    "                        \"C:/Users/atulp/Downloads/perspectiv_labs/data/Output\", cfg)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
